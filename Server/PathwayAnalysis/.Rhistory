tickMarks[i]
pi_1
gaussian_pdf(tickMarks[i], nullmean, nullvar)
gaussian_pdf(zstat[i], nullmean, nullvar)
log_gaussian_pdf <- function(x, mu, sigmasq) {
out <- -0.5*(x-mu)^2/sigmasq - 0.5 * log(2 * pi * sigmasq)
return(out)
}
gaussian_pdf <- function(x, mu, sigmasq) {
return(exp(log_gaussian_pdf(x, mu, sigmasq)))
}
gaussian_pdf(zstat[j], nullmean, nullvar)
log_gaussian_pdf(zstat[j], nullmean, nullvar)
exp(log_gaussian_pdf(zstat[j], nullmean, nullvar))
i = 548
gaussian_pdf(tickMarks[i], nullmean, nullvar)
setwd('E:/OneDrive/PhD/Project/Thesis/4_Pipeline/Pipeline/FDRtest')
#inFile <- "PXD004682_QPROTout_ProgNorm_2up_ThreshResults.csv"
outFile <- "QPROT_FDRtestOut.csv"
example_qprot_fdr <- read.table('PXD004682_QPROTout_QPROTNorm_2up', header = TRUE, sep = '\t')
np <- nrow(example_qprot_fdr)
log_gaussian_pdf <- function(x, mu, sigmasq) {
out <- -0.5*(x-mu)^2/sigmasq - 0.5 * log(2 * pi * sigmasq)
return(out)
}
gaussian_pdf <- function(x, mu, sigmasq) {
return(exp(log_gaussian_pdf(x, mu, sigmasq)))
}
##identifying the range to fit null component to the overall density
bandwidth <- 1.06/(np^0.2)
## initialising parameters
pi_1 <- 0.9
pi_2 <- 0.1
pi_true <- 0.1
nullmean <- rnorm(1, 0 , 0.1)
nullvar <- exp(rnorm(1, 0 , 0.1))
if(np > 10000) {
ntick <- 10000
} else {
ntick <- np
}
zstat <- example_qprot_fdr$Zstatistic
zstat_sort <- sort(zstat)
xmin <- zstat_sort[1] - 0.1
xmax <- zstat_sort[np] + 0.1
tickMarks <- NULL
f0 <- NULL
f1 <- NULL
f <- NULL
for (i in 1:ntick) {
tickMarks[i] <- xmin + i * (xmax - xmin) / ntick
}
for (i in 1:ntick) {
f0[i] <- 0
f0[i] <- f0[i] + gaussian_pdf(tickMarks[i], nullmean, nullvar)
f1[i] <- 0.5 * gaussian_pdf(tickMarks[i], -10, 1) +  0.5 * gaussian_pdf(tickMarks[i], 10, 1)
f[i] <- pi_true * f1[i] + (1.0-pi_true) * f0[i]
}
gaussian_pdf(tickMarks[i], nullmean, nullvar)
f1[i] <- 0.5 * gaussian_pdf(tickMarks[i], -10, 1) +  0.5 * gaussian_pdf(tickMarks[i], 10, 1)
f[i] <- pi_true * f1[i] + (1.0-pi_true) * f0[i]
for (i in 1:ntick) {
f0[i] <- 0
f0[i] <- f0[i] + gaussian_pdf(tickMarks[i], nullmean, nullvar)
f1[i] <- 0.5 * gaussian_pdf(tickMarks[i], -10, 1) +  0.5 * gaussian_pdf(tickMarks[i], 10, 1)
f[i] <- pi_true * f1[i] + (1.0-pi_true) * f0[i]
}
df <- NULL
df0 <- NULL
df1 <- NULL
for (i in 1:np) {
df[i] <- 0
df0[i] <- 0
df1[i] <- 0
}
## Overall nonparametric density for f
denom <- 0
max_y <- 0
tmp_mean <-NULL
for (i in 1:ntick) {
numer <- 0
for (j in 1:np) {
denom <- denom + j
numer <- numer + gaussian_pdf((zstat[j] - tickMarks[i])/bandwidth, 0.0, 1.0)
}
f[i] <- numer / (denom * bandwidth)
## Check mean shift
if(f[i] > max_y) {
max_y <- f[i]
tmp_mean <- tickMarks[i]
}
}
nullmean <- tmp_mean
## Fit gaussian unif
zz <- matrix(nrow = np, ncol = 2)
z_min <- zstat_sort[1] - 0.1
z_max <- zstat_sort[np] + 0.1
old_mean <- NULL
old_var <- NULL
for (k in 1:np) {
zz[k, 1] <- 0.1
zz[k, 2] <- 0.9
zz[k, 1] <- zz[k, 1] * exp(rnorm(1, 0 , 0.1))
zz[k, 2] <- zz[k, 2] * exp(rnorm(1, 0 , 0.1))
tmp_denom <- 0
tmp_denom <- tmp_denom + zz[k, 1]
tmp_denom <- tmp_denom + zz[k, 2]
zz[k, 1] <- zz[k, 1] / tmp_denom
zz[k, 2] <- zz[k, 2] / tmp_denom
}
counter <- 0
tol <- 1000
tmpl <- NULL
(rnorm(1, 0 , 0.1))
exp(rnorm(1, 0 , 0.1))
counter <- 0
tol <- 1000
tmpl <- NULL
while(tol > 0.00001 && counter < 100) {
old_mean <- nullmean
old_var <- nullvar
tmp_num <- 0
tmp_denom <- 0
for (i in 1:np) {
tmp_num <- tmp_num + (zstat[i] * zz[i, 1])
}
for (i in 1:np) {
tmp_denom <- tmp_denom + (zz[i, 1])
}
# if(tmp_denom > 0) {
#     nullmean <- tmp_num / tmp_denom
# } else{
#     nullmean <- 0
# }
tmp_num <- 0
tmp_denom <- 0
for (i in 1:np) {
tmp_num <- tmp_num + ((zstat[i] - nullmean) ^ 2) * (zz[i, 1])
}
for (i in 1:np) {
tmp_denom <- tmp_denom + (zz[i, 1])
}
if(tmp_denom > 0) {
nullvar <- tmp_num / tmp_denom
} else{
nullvar <- 0
}
for (i in 1:np) {
tmpl[1] <- pi_1 * gaussian_pdf(zstat[i], nullmean, nullvar)
tmpl[2] <- pi_2 / (z_max - z_min)
tmp_denom <- 0
tmp_denom <- tmp_denom + tmpl[1]
tmp_denom <- tmp_denom + tmpl[2]
if (tmp_denom > 0) {
zz[i, 1] <- tmpl[1] / tmp_denom
zz[i, 2] <- tmpl[2] / tmp_denom
} else {
zz[i, 1] <- 0
zz[i, 2] <- 0
}
}
tmp <- 0
for (i in 1:np) {
tmp <- tmp + zz[i, 1]
}
tmp <- tmp / np
pi_1 <- tmp
tmp <- 0
for (i in 1:np) {
tmp <- tmp + zz[i, 2]
}
tmp <- tmp / np
pi_2 <- tmp
tol <- 0
tol <- tol + abs(old_mean - nullmean)
tol <- tol + abs(old_var - nullvar)
counter <- counter + 1
}
## Evaluate f0 and df0
for (i in 1:ntick) {
tmp <- 0
tmp <- tmp + (pi_1 * gaussian_pdf(tickMarks[i], nullmean, nullvar))
tmp <- tmp / (1.0 - pi_2)
f0[i] <- tmp
}
for(i in 1:np) {
tmp <- 0
tmp <- tmp + (pi_1 * gaussian_pdf(zstat[i], nullmean, nullvar))
tmp <- tmp / (1.0 - pi_2)
df0[i] <- tmp
}
pi_true <- pi_2
mm <- 0
vv <- 0
mm <- mm + nullmean
vv <- vv + nullvar
z_left = mm - sqrt(vv)
z_right =  mm + sqrt(vv)
f0_temp <- NULL
for (i in 1:ntick) {
f0_temp[i]<- f0[i]
}
f_ord <- sort(f)
tol_diff <- f_ord[np] * 0.01
ct <- 0
ntry <- 10000
rescale_factor <- 1
is_under <- 1
is_over <- 0
while(rescale_factor > 0 && ct < ntry) {
#if(ct > 0 && ct %% 1000 == 0) {
#    print('error')
#}
for(i in 1:ntick) {
tmp <- 0.0
tmp <- tmp + (pi_1 * gaussian_pdf(tickMarks[i], nullmean, (nullvar * rescale_factor)))
tmp <- tmp / (1.0 - pi_2)
f0[i] <-  tmp # equalizing the height as it was obtained before rescaling
}
# f0_factor is updated as we shrink the variances
i <- 1
while(tickMarks[i] < nullmean) {
i <- i + 1
}
f0_factor = f[i] / f0[i]
for (i in 1:ntick) {
f0[i] <- f0[i] * f0_factor
}
# check if f0_temp falls under the non-parametric estimate of f
is_under <- 1
for (i in 1:ntick) {
if(tickMarks[i] > z_left && tickMarks[i] < z_right) {
if(f0[i] > (f[i]+tol_diff)) {
is_under <- 0
}
}
}
if(is_under==1) {
nullvar <- nullvar * rescale_factor
print(paste('Found re-scaling factor: ', rescale_factor, sep = ''))
break
}
rescale_factor <- rescale_factor * 0.99
ct <- ct + 1
}
if(ct == ntry) {
print(paste('Unable to rescale variances. Last try: ', rescale_factor, sep = ''))
}
#If it satisfied in the first try, that means we can inflate the variances
if(ct == 0) {
print("Inflating variances")
ct <- 0
rescale_factor <- 1
while(rescale_factor > 0 && ct < ntry) {
#if(ct > 0 && ct %% 1000 == 0) {
#    print('error')
#}
for(i in 1:ntick) {
tmp <- 0.0
tmp <- tmp + (pi_1 * gaussian_pdf(tickMarks[i], nullmean, (nullvar * rescale_factor)))
tmp <- tmp / (1.0 - pi_2)
f0[i] <-  tmp # equalizing the height as it was obtained before rescaling
}
# f0_factor is updated as we shrink the variances
i <- 1
while(tickMarks[i] < nullmean) {
i <- i + 1
}
f0_factor = f[i] / f0[i]
for (i in 1:ntick) {
f0[i] <- f0[i] * f0_factor
}
# check if f0_temp falls under the non-parametric estimate of f
is_over <- 0
for (i in 1:ntick) {
if(tickMarks[i] > z_left && tickMarks[i] < z_right) {
if(f0[i] > (f[i]+tol_diff)) {
is_over <- 1
}
}
}
if(is_over==1) {
nullvar <- nullvar * rescale_factor
print(paste('Found re-scaling factor: ', rescale_factor, sep = ''))
break
}
rescale_factor <- rescale_factor * 1.05
ct <- ct + 1
}
}
for(i in 1:ntick) {
if(f[i] < f0[i]) {
f[i] = f0[i]
}
}
# re-evaluate f0
for(i in 1:ntick) {
tmp = 0.0
tmp <- tmp + (pi_1 * gaussian_pdf(tickMarks[i], nullmean, nullvar))
tmp <- tmp / (1.0 - pi_2)
f0[i] = tmp
}
#identifying the range to fit null component to the overall density
tmp_r <- NULL
mm <- 0
vv <- 0
mm <- mm + nullmean
vv <- vv + nullvar
tmp <- 1
for(i in 1:ntick) {
if(abs(tickMarks[i] - mm) < 3.0 * sqrt(vv)) {
tmp_r = f[i] / f0[i]
if(tmp_r < tmp) {
tmp <- tmp_r
}
}
}
pi_true = 1 - tmp
print(paste('The estimate of pi(DE) is: ', pi_true, sep = ''))
# Evaluate densities
for(j in 1:np) {
## Evaluate f0
df0[j] <- pi_1 * gaussian_pdf(zstat[j], nullmean, nullvar)
df0[j] <- df0[j] / (1.0 - pi_2)
## Evaluate df
i = 1
while(tickMarks[i] < zstat[j]  && i <= ntick) {
i <- i + 1
}
df[j] = f[i] + (f[i+1] - f[i]) / (tickMarks[i+1] - tickMarks[i]) * (zstat[j] - tickMarks[i])
}
## Evaluate f1
for(i in 1:ntick) {
f1[i] <- ( f[i] - (1.0-pi_true) * f0[i] ) / pi_true
if(f1[i] < 1e-100) {
f1[i] <- 1e-100
}
}
for(i in 1:np) {
tmp <- 0
tmp <- tmp + (pi_1 * gaussian_pdf(zstat[i], nullmean, nullvar))
tmp <- tmp / (1.0 - pi_2)
df0[i] <- tmp
}
zstat[i]
gaussian_pdf(zstat[i], nullmean, nullvar)
gaussian_pdf(tickMarks[i], nullmean, nullvar)
aussian_pdf(tickMarks[i], nullmean, nullvar)
gaussian_pdf(tickMarks[i], nullmean, nullvar)
gaussian_pdf(zstat[i], nullmean, nullvar)
gaussian_pdf(zstat[i], nullmean, nullvar)
gaussian_pdf((zstat[j] - tickMarks[i])/bandwidth, 0.0, 1.0)
gaussian_pdf(tickMarks[i], -10, 1) +  0.5 * gaussian_pdf(tickMarks[i], 10, 1)
library(clusterProfiler)
sessionInfo()
library(clusterProfiler)
#library(ReactomePA)
#library(data.table)
#library(stringr)
library(tidyr)
# SET THE DESIRED ORGANISM HERE
organism = "org.Hs.eg.db"
#BiocManager::install(organism, character.only = TRUE)
library(organism, character.only = TRUE)
setwd('E:/OneDrive/PhD/Project/Thesis/4_Pipeline/Pipeline/Server/PathwayAnalysis')
fdrThresh <- 0.05
#fileIn <- 'PXD004682_QPROTout_QPROTNorm_1up'
#norm <- "QPROT"
#fileIn <- 'PXD004682_QPROTout_NoNorm_1up'
#norm <- "noNorm"
fileIn <- 'QPROT_FDRcomp'
#norm <- "Log2"
#fileOut <- paste ("PAout_", fileIn, '_', fdrThresh, sep = '')
fileOut <- paste ("results/PAout_", fileIn, '_QPROT', fdrThresh, sep = '')
# Reads in file and removes top 2 lines
#qprot_out <- read.table(fileIn, header = TRUE, sep = '\t')
#qprot_out <- qprot_out[,c(1:17)]
qprot_out <- read.csv(paste(fileIn, '.csv', sep =''), header = TRUE)
# Reads in file and removes top 2 lines
#qprot_out <- read.table(fileIn, header = TRUE, sep = '\t')
#qprot_out <- qprot_out[,c(1:17)]
qprot_out <- read.csv(paste(fileIn, '.csv', sep =''), header = TRUE)
qprot_out <- qprot_out[,c(2:18)]
View(qprot_out)
setwd('E:/OneDrive/PhD/Project/Thesis/4_Pipeline/Pipeline/Server/PathwayAnalysis')
#norm <- "Log2"
#fileOut <- paste ("PAout_", fileIn, '_', fdrThresh, sep = '')
fileOut <- paste ("results/PAout_", fileIn, '_QPROT', fdrThresh, sep = '')
# Reads in file and removes top 2 lines
#qprot_out <- read.table(fileIn, header = TRUE, sep = '\t')
#qprot_out <- qprot_out[,c(1:17)]
qprot_out <- read.csv(paste(fileIn, '.csv', sep =''), header = TRUE)
qprot_out <- qprot_out[,c(2:18)]
# Column names
colnames(qprot_out) <- c("Protein", "N1", "N2", "N3", "N4", "N5", "N6", "N7",
"T1", "T2", "T3", "T4", "T5", "T6", "LogFoldChange",
"Zstatistic", "fdr")
qprot_out <- qprot_out[order(qprot_out$fdr), ]
## create dataframe to store number of significant terms for each threshold
thresholdResults <- data.frame(matrix(ncol = 8, nrow = 0))
headers <- c("Normalisation", "Threshold", "Go_BP", "Go_MF", "Go_CC",
"Total", 'DEs')
colnames(thresholdResults) <- headers
## Seperate the protein name so the Unipropt accesion can be used
protAcc <- qprot_out %>% separate(Protein, c("SP", "Uniprot_Acc", "Entrez"), sep = "\\|")
## List of background proteins for enrichment analysis
BG_prots <- protAcc$Uniprot_Acc
BG_react <- select(org.Hs.eg.db, BG_prots, "ENTREZID", "UNIPROT")
## Initialises vector of results
results <- NULL
# Create list of DE proteins and all proteins
DE_prots <- as.vector(subset(protAcc$Uniprot_Acc, protAcc$fdr < fdrThresh))
DE <- length(DE_prots)
NonDE_prots <- as.vector(subset(protAcc$Uniprot_Acc, protAcc$fdr >= fdrThresh))
nonDE <- length(NonDE_prots)
if (DE > 0) {
print(paste("Number of DEs: ", DE, sep = ""))
flush.console()
print("Performing GO analysis....")
flush.console()
# Get functional annotation chart as R object and save to file
GO_BPresult <- enrichGO(gene = DE_prots,
OrgDb = 'org.Hs.eg.db',
keyType = 'UNIPROT',
ont = 'BP',
universe = BG_prots,
pvalueCutoff = 0.05,
pAdjustMethod = 'BH')
GO_BPsimply <- simplify(GO_BPresult,
cutoff = 0.7,
by = "p.adjust",
select_fun = min)
GOBPnum <- nrow(GO_BPsimply)
GO_MFresult <- enrichGO(gene = DE_prots,
OrgDb = 'org.Hs.eg.db',
keyType = 'UNIPROT',
ont = 'MF',
universe = BG_prots,
pvalueCutoff = 0.05,
pAdjustMethod = 'BH')
GO_MFsimply <- simplify(GO_MFresult,
cutoff = 0.7,
by = "p.adjust",
select_fun = min)
GOMFnum <- nrow(GO_MFsimply)
GO_CCresult <- enrichGO(gene = DE_prots,
OrgDb = 'org.Hs.eg.db',
keyType = 'UNIPROT',
ont = 'CC',
universe = BG_prots,
pvalueCutoff = 0.05,
pAdjustMethod = 'BH')
GO_CCsimply <- simplify(GO_CCresult,
cutoff = 0.7,
by = "p.adjust",
select_fun = min)
GOCCnum <- nrow(GO_CCsimply)
totGO <- GOBPnum + GOMFnum + GOCCnum
print(paste("Number of GO terms: ", totGO, sep = ""))
flush.console()
# print("Performing KEGG analysis")
# flush.console()
# KEGGresult <- enrichKEGG(gene = DE_prots,
#                          organism = "hsa",
#                          keyType = 'uniprot',
#                          universe = BG_prots,
#                          pvalueCutoff = 0.05,
#                          pAdjustMethod = 'BH')
# KEGGnum <- nrow(KEGGresult)
# print(paste("Number of KEGG terms: ", KEGGnum , sep = ""))
# flush.console()
#
# totNum <- totGO + KEGGnum
#   ## Summary of results
#   results <- data.frame(Threshold = fdrThresh, Go_BP = GOBPnum, Go_MF = GOMFnum,
#                         Go_CC = GOCCnum,  Kegg_Path = KEGGnum , Total = totNum, DEs = DE)
#
#   ## Add to table of results
#   thresholdResults <- rbind(thresholdResults, results)
#
# } else {
#   results <- data.frame(Threshold =fdrThresh, Go_BP = 0, Go_MF = 0,
#                         Go_CC = 0, Kegg_Path = 0, Total = 0, DEs = DE)
#   thresholdResults <- rbind(thresholdResults, results)
## Summary of results
results <- data.frame(Normalisation = norm, Threshold = fdrThresh, Go_BP = GOBPnum, Go_MF = GOMFnum,
Go_CC = GOCCnum, Total = totGO, DEs = DE)
## Add to table of results
thresholdResults <- rbind(thresholdResults, results)
} else {
print(paste("No DE proteins at threshold: ", fdrThresh, sep = ""))
flush.console()
results <- data.frame(Normalisation = norm, Threshold =fdrThresh, Go_BP = 0, Go_MF = 0,
Go_CC = 0, Total = 0, DEs = DE)
thresholdResults <- rbind(thresholdResults, results)
}
#fileIn <- 'PXD004682_QPROTout_QPROTNorm_1up'
#norm <- "QPROT"
#fileIn <- 'PXD004682_QPROTout_NoNorm_1up'
norm <- "noNorm"
#                         Go_CC = GOCCnum,  Kegg_Path = KEGGnum , Total = totNum, DEs = DE)
#
#   ## Add to table of results
#   thresholdResults <- rbind(thresholdResults, results)
#
# } else {
#   results <- data.frame(Threshold =fdrThresh, Go_BP = 0, Go_MF = 0,
#                         Go_CC = 0, Kegg_Path = 0, Total = 0, DEs = DE)
#   thresholdResults <- rbind(thresholdResults, results)
## Summary of results
results <- data.frame(Normalisation = norm, Threshold = fdrThresh, Go_BP = GOBPnum, Go_MF = GOMFnum,
Go_CC = GOCCnum, Total = totGO, DEs = DE)
